{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c47709eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict, deque\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96921237",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../\"\n",
    "DATA  = ROOT + \"datasets/\"\n",
    "MODELS = ROOT + \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0e3ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPT:\n",
    "    def __init__(self, head, parents):\n",
    "        self.head = head\n",
    "        self.parents = parents\n",
    "        self.entries = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        comma = \", \"\n",
    "        if len(self.parents) == 0:\n",
    "            return f\"probability ( {self.head.name} ) {{\" + \"\\n\" \\\n",
    "                f\"  table {comma.join ( map(str,self.entries[tuple()].values () ))};\" + \"\\n\" \\\n",
    "                f\"}}\" + \"\\n\"\n",
    "        else:\n",
    "            return f\"probability ( {self.head.name} | {comma.join ( [p.name for p in self.parents ] )} ) {{\" + \"\\n\" + \\\n",
    "                \"\\n\".join ( [  \\\n",
    "                    f\"  ({comma.join(names)}) {comma.join(map(str,values.values ()))};\" \\\n",
    "                    for names,values in self.entries.items () \\\n",
    "                ] ) + \"\\n}\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f58e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, name, values):\n",
    "        self.name = name\n",
    "        self.values = values \n",
    "        self.cpt = None\n",
    "\n",
    "    def __str__(self):\n",
    "        comma = \", \"\n",
    "        return f\"variable {self.name} {{\" + \"\\n\" \\\n",
    "             + f\"  type discrete [ {len(self.values)} ] {{ {(comma.join(self.values))} }};\" + \"\\n\" \\\n",
    "             + f\"}}\" + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c68a26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNetwork:\n",
    "    def __init__(self, input_file):\n",
    "        with open(input_file) as f:\n",
    "            lines = f.readlines()\n",
    "        self.variables = {}\n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = lines[i].lstrip().rstrip().replace('/', '-')\n",
    "        i = 0\n",
    "        while i < len(lines) and not lines[i].startswith(\"probability\"):\n",
    "            if lines[i].startswith(\"variable\"):\n",
    "                variable_name = lines[i].rstrip().split(' ')[1]\n",
    "                i += 1\n",
    "                variable_def = lines[i].rstrip().split(' ')\n",
    "                assert(variable_def[1] == 'discrete')\n",
    "                variable_values = [x for x in variable_def[6:-1]]\n",
    "                for j in range(len(variable_values)):\n",
    "                    variable_values[j] = re.sub(r'\\(|\\)|,', '', variable_values[j])\n",
    "                variable = Variable(variable_name, variable_values)\n",
    "                self.variables[variable_name] = variable\n",
    "            i += 1\n",
    "        while i < len(lines):\n",
    "            if lines[i].startswith('probability'):\n",
    "                split = lines[i].split(' ')\n",
    "                target_variable_name = split[2]\n",
    "                variable = self.variables[target_variable_name]\n",
    "                parents = [self.variables[x.rstrip().lstrip().replace(',', '')] for x in split[4:-2]]\n",
    "                assert(variable.name == split[2])\n",
    "                cpt = CPT(variable, parents)\n",
    "                i += 1\n",
    "                if len(parents) > 0:\n",
    "                    nb_lines = 1\n",
    "                    for p in parents:\n",
    "                        nb_lines *= len(p.values)\n",
    "                    for _ in range(nb_lines):\n",
    "                        cpt_line = [x for x in re.sub(r'\\(|\\)|,', '', lines[i][:-1]).split()]\n",
    "                        parent_values = tuple([x for x in cpt_line[:len(parents)]])\n",
    "                        probabilities = [float(p) for p in cpt_line[len(parents):]]\n",
    "                        cpt.entries[parent_values] = { v:p for v,p in zip(variable.values,probabilities) }\n",
    "                        i += 1\n",
    "                else:\n",
    "                    cpt_line = [x for x in re.sub(r'\\(|\\)|,', '', lines[i][:-1]).split()]\n",
    "                    probabilities = [float(p) for p in cpt_line[1:]]\n",
    "                    cpt.entries[tuple()] = { v:p for v,p in zip(variable.values,probabilities) }\n",
    "                variable.cpt = cpt\n",
    "            i += 1\n",
    "\n",
    "    def write(self,filename):\n",
    "        with open(filename,\"w\") as file:\n",
    "            for var in self.variables.values ():\n",
    "                file.write(str(var))\n",
    "            for var in self.variables.values ():\n",
    "                file.write(str(var.cpt))\n",
    "\n",
    "    def P_Yisy_given_parents_x(self,Y,y,x=tuple()):\n",
    "        return self.variables[Y].cpt.entries[x][y]\n",
    "\n",
    "    def P_Yisy_given_parents(self,Y,y,pa={}):\n",
    "        x = tuple([ pa[parent.name] for parent in self.variables[Y].cpt.parents ])\n",
    "        return self.P_Yisy_given_parents_x(Y,y,x)\n",
    "\n",
    "    def _get_children(self):\n",
    "        children = defaultdict(list)\n",
    "        for var in self.variables.values():\n",
    "            for parent in var.cpt.parents:\n",
    "                children[parent.name].append(var.name)\n",
    "        return children\n",
    "\n",
    "    def _normalize(self, dist):\n",
    "        total = sum(dist.values())\n",
    "        return {k: v / total for k, v in dist.items() if total > 0}\n",
    "\n",
    "    def _get_pi_contribution(self, pname, pval, pi_msgs, evidence):\n",
    "        if pname in pi_msgs:\n",
    "            return pi_msgs[pname][pval]\n",
    "        elif pname in evidence:\n",
    "            return 1.0 if evidence[pname] == pval else 0.0\n",
    "        else:\n",
    "            return 1.0 / len(self.variables[pname].values)\n",
    "\n",
    "    def _send_messages_to_root(self, node, evidence, children, lambda_msgs):\n",
    "        if node in lambda_msgs:\n",
    "            return lambda_msgs[node]\n",
    "\n",
    "        var = self.variables[node]\n",
    "        lambda_msg = {val: 1.0 for val in var.values}\n",
    "\n",
    "        for child in children[node]:\n",
    "            child_lambda = self._send_messages_to_root(child, evidence, children, lambda_msgs)\n",
    "            child_var = self.variables[child]\n",
    "            parent_names = [p.name for p in child_var.cpt.parents]\n",
    "\n",
    "            new_lambda = {}\n",
    "            for xi in var.values:\n",
    "                msg = 0.0\n",
    "                for xj in child_var.values:\n",
    "                    def get_vals(pname):\n",
    "                        if pname == node:\n",
    "                            return [xi]\n",
    "                        elif pname in evidence:\n",
    "                            return [evidence[pname]]\n",
    "                        else:\n",
    "                            return self.variables[pname].values\n",
    "\n",
    "                    all_pa_vals = itertools.product(*[get_vals(pname) for pname in parent_names])\n",
    "\n",
    "                    for pa in all_pa_vals:\n",
    "                        pa_dict = dict(zip(parent_names, pa))\n",
    "                        pa_vals = tuple(pa_dict[p.name] for p in child_var.cpt.parents)\n",
    "                        prob = child_var.cpt.entries[pa_vals][xj]\n",
    "                        msg += prob * child_lambda[xj]\n",
    "                new_lambda[xi] = lambda_msg[xi] * msg\n",
    "            lambda_msg = new_lambda\n",
    "\n",
    "        if node in evidence:\n",
    "            observed = evidence[node]\n",
    "            lambda_msg = {val: (1.0 if val == observed else 0.0) for val in var.values}\n",
    "\n",
    "        lambda_msgs[node] = lambda_msg\n",
    "        return lambda_msg\n",
    "\n",
    "    def _send_messages_from_root(self, node, pi_msg, evidence, children, lambda_msgs, beliefs, pi_msgs):\n",
    "        var = self.variables[node]\n",
    "        lambda_msg = lambda_msgs[node]\n",
    "        belief = {val: pi_msg[val] * lambda_msg[val] for val in var.values}\n",
    "        beliefs[node] = self._normalize(belief)\n",
    "        pi_msgs[node] = pi_msg\n",
    "\n",
    "        for child in children[node]:\n",
    "            child_var = self.variables[child]\n",
    "            parent_names = [p.name for p in child_var.cpt.parents]\n",
    "            child_pi = {xj: 0.0 for xj in child_var.values}\n",
    "\n",
    "            for xj in child_var.values:\n",
    "                total = 0.0\n",
    "                def get_vals(pname):\n",
    "                    if pname in evidence:\n",
    "                        return [evidence[pname]]\n",
    "                    else:\n",
    "                        return self.variables[pname].values\n",
    "\n",
    "                all_pa_vals = itertools.product(*[get_vals(pname) for pname in parent_names])\n",
    "\n",
    "                for pa in all_pa_vals:\n",
    "                    pa_dict = dict(zip(parent_names, pa))\n",
    "                    pa_vals = tuple(pa_dict[p.name] for p in child_var.cpt.parents)\n",
    "                    prob = child_var.cpt.entries[pa_vals][xj]\n",
    "\n",
    "                    contrib = 1.0\n",
    "                    for pname, pval in pa_dict.items():\n",
    "                        contrib *= self._get_pi_contribution(pname, pval, pi_msgs, evidence)\n",
    "\n",
    "                    total += contrib * prob\n",
    "\n",
    "                child_pi[xj] = total\n",
    "\n",
    "            self._send_messages_from_root(child, child_pi, evidence, children, lambda_msgs, beliefs, pi_msgs)\n",
    "\n",
    "    def query_marginal(self, query_var, evidence):\n",
    "        children = self._get_children()\n",
    "        lambda_msgs = {}\n",
    "        beliefs = {}\n",
    "        pi_msgs = {}\n",
    "\n",
    "        root = next(iter(evidence)) if evidence else query_var\n",
    "        self._send_messages_to_root(root, evidence, children, lambda_msgs)\n",
    "\n",
    "        root_var = self.variables[root]\n",
    "        if root_var.cpt.parents:\n",
    "            root_pi = {val: 1.0 for val in root_var.values}\n",
    "        else:\n",
    "            root_pi = root_var.cpt.entries[tuple()]\n",
    "\n",
    "        self._send_messages_from_root(root, root_pi, evidence, children, lambda_msgs, beliefs, pi_msgs)\n",
    "\n",
    "        return beliefs[query_var]\n",
    "    \n",
    "    def query_joint(self, var1, var2, evidence):\n",
    "        joint_dist = {}\n",
    "        for val1 in self.variables[var1].values:\n",
    "            joint_dist[val1] = {}\n",
    "            for val2 in self.variables[var2].values:\n",
    "                extended_evidence = dict(evidence)\n",
    "                extended_evidence[var2] = val2\n",
    "                marginal_var1 = self.query_marginal(var1, {**extended_evidence, var2: val2})\n",
    "                marginal_var2 = self.query_marginal(var2, evidence)\n",
    "                joint_dist[val1][val2] = marginal_var1[val1] * marginal_var2[val2]\n",
    "        return self._normalize_nested(joint_dist)\n",
    "\n",
    "    def _normalize_nested(self, joint_dist):\n",
    "        total = sum(v for d in joint_dist.values() for v in d.values())\n",
    "        if total == 0:\n",
    "            return joint_dist\n",
    "        for k1 in joint_dist:\n",
    "            for k2 in joint_dist[k1]:\n",
    "                joint_dist[k1][k2] /= total\n",
    "        return joint_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5caa355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing inference for single variable (|Y|=1)...\n",
      "\n",
      "Test 1: P(HISTORY=1 | LVFAILURE=1)\n",
      "Expected: 0.990000\n",
      "Inferred: 0.990000\n",
      "\n",
      "Test 2: P(HYPOVOLEMIA)\n",
      "Inference result: {'0': 0.2, '1': 0.8}\n",
      "Expected CPT:     {'0': 0.2, '1': 0.8}\n"
     ]
    }
   ],
   "source": [
    "bn = BayesianNetwork(f\"{MODELS}/alarm/alarm_complete.bif\")\n",
    "\n",
    "print(\"Testing inference for single variable (|Y|=1)...\\n\")\n",
    "\n",
    "print(\"Test 1: P(HISTORY=1 | LVFAILURE=1)\")\n",
    "inferred = bn.query_marginal(\"HISTORY\", {\"LVFAILURE\": \"1\"})\n",
    "expected = bn.P_Yisy_given_parents(\"HISTORY\", \"1\", {\"LVFAILURE\": \"1\"})\n",
    "print(f\"Expected: {expected:.6f}\")\n",
    "print(f\"Inferred: {inferred['1']:.6f}\")\n",
    "\n",
    "print(\"\\nTest 2: P(HYPOVOLEMIA)\")\n",
    "inferred = bn.query_marginal(\"HYPOVOLEMIA\", {})\n",
    "expected = {\n",
    "    v: bn.P_Yisy_given_parents(\"HYPOVOLEMIA\", v)\n",
    "    for v in bn.variables[\"HYPOVOLEMIA\"].values\n",
    "}\n",
    "print(f\"Inference result: {inferred}\")\n",
    "print(f\"Expected CPT:     {expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d26bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing inference for joint distribution (|Y|=2)...\n",
      "\n",
      "Expected P(HISTORY=1, LVFAILURE=1): 0.891000\n",
      "Inferred : 0.940500\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing inference for joint distribution (|Y|=2)...\\n\")\n",
    "bn = BayesianNetwork(f\"{MODELS}/alarm/alarm_complete.bif\")\n",
    "\n",
    "print(\"Test 1: P(HISTORY=1, LVFAILURE=1)\")\n",
    "inferred_joint = bn.query_joint(\"HISTORY\", \"LVFAILURE\", {})\n",
    "expected_joint = 0.891  # P(HISTORY=1, LVFAILURE=1) = 0.9 * 0.99\n",
    "print(f\"Expected approximation: {expected_joint:.6f}\")\n",
    "print(f\"Inferred :              {inferred_joint['1']['1']:.6f}\")\n",
    "\n",
    "print(\"Test 2: P(HR=2, CO=3)\")\n",
    "inferred_joint = bn.query_joint(\"HR\", \"CO\", {})\n",
    "expected_joint = 0.8 * 0.6  # P(HR=2) * P(CO=3 | HR=2)\n",
    "print(f\"Expected approximation: {expected_joint:.6f}\")\n",
    "print(f\"Inferred :              {inferred_joint['2']['3']:.6f}\")\n",
    "\n",
    "print(\"Test 3: P(CATECHOL=2, BP=3)\")\n",
    "inferred_joint = bn.query_joint(\"CATECHOL\", \"BP\", {})\n",
    "expected_joint = 0.2 * 0.5\n",
    "print(f\"Expected approximation: {expected_joint:.6f}\")\n",
    "print(f\"Inferred :              {inferred_joint['2']['3']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
